# 🧠 Product Serving: 머신러닝 모델 Serving의 종류와 다양한 패턴

> 본 문서는 네이버 커넥트 재단의 Product Serving 강의를 바탕으로 정리되었습니다.  
> 목적: 실제 환경에서 머신러닝 모델을 효과적으로 배포(Serving)하기 위한 개념 및 설계 패턴 학습.

---

## 📍 1. Serving: 모델을 세상으로

### 1.1 Serving의 정의

- **Serving**이란 “모델의 예측 결과를 요청한 클라이언트(Client)에게 제공하는 과정”을 의미합니다.
- 즉, **머신러닝 모델을 실제 운영 환경(Production)**에서 사용할 수 있도록 배포하는 것을 말합니다.
- 연구 단계(Research)에서 만들어진 모델을 실제 서비스에 “서비스화(Serving)”하는 과정입니다.

> 💡 비유:  
> Research 단계에서 만든 요리를 실제 식탁(Production)에 “서빙”하는 과정.  
> 주문(Request)이 들어오면, 모델이 예측(Output)을 반환하여 클라이언트(Client)에게 제공.

---

### 1.2 Serving의 대표 예시

| 예시 | 설명 |
|------|------|
| 🎬 **YouTube 추천 시스템** | 개인화된 영상 추천 (Online Serving) |
| 🌍 **DeepL 번역기** | 입력 언어 → 출력 언어 실시간 번역 |
| 🚗 **쏘카 차량 상태 분류** | 차량 외관 이미지를 분석해 세차 필요성 분류 |

---

### 1.3 Serving의 종류

#### (1) **Batch Serving**
- **일괄 처리 방식**으로 일정 주기(시간 단위 등)에 데이터를 모아 예측을 수행.  
- 예: 매일 20시에 전체 데이터를 예측 후 DB에 저장 → 서비스는 해당 결과를 활용.
- 실시간 응답이 중요하지 않은 경우에 적합.

#### (2) **Online (Real-Time) Serving**
- **요청 시 즉시 예측**하는 방식.
- 예: API Request 시 데이터를 함께 보내고 즉각적인 응답을 받음.
- 실시간 응답, 동적 데이터, 개인화 서비스에 적합.

---

### 1.4 어떤 Serving을 사용할까?

| 구분 | Batch Serving | Online Serving |
|------|----------------|----------------|
| ⚙️ 상황 | 실시간 응답이 중요하지 않음 / 대량 데이터 / 정기적 작업 | 실시간 응답 중요 / 맞춤형 응답 / 데이터가 지속적으로 변함 |
| 👥 인력 | 인력이 적을 때 유리 | API 서버, 실시간 처리 경험 필요 |
| 💾 데이터 저장 | RDB, DW 중심 | 요청 시 데이터 포함 전달 |
| 🧩 예시 | Netflix 추천, DoorDash | 유튜브 추천, 은행 사기 탐지 |

---

## 🧱 2. 단순한 Serving 패턴 (Machine Learning Design Patterns)

> 머신러닝 시스템은 **Data + Model + Code**의 복합 구조이므로,  
> 일반 소프트웨어와 달리 ML 특화된 디자인 패턴이 필요합니다.

### 2.1 디자인 패턴의 개념

- 반복되는 문제 해결 방식을 구조화한 **템플릿(Template)**.
- 목적: 재사용성, 가독성, 확장성 향상.
- “이번 Serving은 Batch 패턴으로 가자!” 처럼 커뮤니케이션 도구로도 사용됨.
- 반대로 **Anti-Pattern**은 지양해야 할 비효율적 구조를 의미.

---

### 2.2 머신러닝 디자인 패턴의 필요성

- 일반 개발과 달리 데이터와 모델 관리, 대용량 처리, 예측 지연 등의 이슈 존재.
- 학습–예측–운영 과정에서 생긴 노하우가 ‘패턴화’됨.
- 완벽한 정답은 없으며, **“상황에 맞는 설계 감각”**을 익히는 것이 중요.

---

## ⚙️ Serving의 4가지 기본 패턴

| 구분 | Serving 유형 | 특징 요약 |
|------|---------------|------------|
| 1️⃣ **Batch 패턴** | Batch Serving | 주기적 Job 수행, 예측 결과를 DB에 저장 |
| 2️⃣ **Web Single 패턴** | Online Serving | 단일 API 서버로 모델을 로드하여 즉시 예측 |
| 3️⃣ **Synchronous 패턴** | Online Serving | 요청-응답이 순차적으로 진행되는 동기식 구조 |
| 4️⃣ **Asynchronous 패턴** | Online Serving | 메시지 큐 기반 비동기 구조 (예: Kafka) |

---

### 🔹 (1) Batch 패턴

#### 개념
- 일정 주기로 모델 예측을 수행하고, 결과를 DB에 저장해 활용.
- 실시간성이 필요 없는 경우에 적합.

#### 구성 요소
- **Job Management Server**: Apache Airflow 등 스케줄링 담당.
- **Job**: 모델 로드 + 데이터 로드 + 예측 수행 단위.
- **Data Storage**: 결과를 저장하는 DB 또는 DW.

#### 장점
- API 서버 불필요, 단순 구조.
- 기존 코드 재사용 가능.
- 서버 자원 관리 유연.

#### 단점
- 별도 스케줄러 필요.
- 예측 결과 반영이 즉시 이루어지지 않음.

#### 예시
- Netflix 추천 모델 (1시간~24시간 단위 예측 저장)

---

### 🔹 (2) Web Single 패턴

#### 개념
- 모델을 포함한 단일 API 서버(FastAPI, Flask 등)를 배포하여 요청 시 즉시 예측.
- **FastAPI → `/predict`** 와 같은 엔드포인트를 구성.

#### 구성 요소
- **Client**: 앱, 웹, 혹은 백엔드 서버.
- **Model Server**: FastAPI, Flask로 구성된 단일 서버.
- **Load Balancer**: Nginx, AWS ELB 등으로 트래픽 분산.

#### 장점
- 구조 단순, 개발 진입 장벽 낮음.
- 빠른 프로토타이핑에 적합.

#### 단점
- 모델 변경 시 전체 재배포 필요.
- 대형 모델일 경우 로드 지연 발생.

---

### 🔹 (3) Synchronous 패턴

#### 개념
- 요청이 완료될 때까지 기다리는 **동기식(Blocking)** 구조.
- 대부분의 REST API는 기본적으로 이 방식.

#### 장점
- 아키텍처 단순, 워크플로우 명확.
- 요청-응답 기반 서비스에 적합.

#### 단점
- 요청이 몰릴 경우 병목 발생.
- 예측 지연 시 사용자 경험 저하.

#### 예시
- 예측 결과에 따라 UI가 즉시 달라지는 경우  
  (예: “강아지 vs 고양이” 이미지 분류 결과에 따라 페이지 변경)

---

### 🔹 (4) Asynchronous 패턴

#### 개념
- 클라이언트와 예측 서버 사이에 **메시지 큐(Queue)**를 둬 요청을 비동기적으로 처리.
- 대표 도구: **Apache Kafka, RabbitMQ 등**.

#### 장점
- 클라이언트와 예측 프로세스 분리 → 독립적 확장 가능.
- 요청과 응답을 병렬적으로 처리 가능.

#### 단점
- 메시지 큐 시스템 구축 필요.
- 실시간성이 약간 떨어질 수 있음.

#### 예시
- 대규모 요청 처리, 대기열 기반 서비스 구조 (예: 대량 이미지 분석 요청 등)

---

## 🚫 3. Anti-Serving 패턴

> 권장되지 않는 구조이지만, 실제 환경에서 자주 발생함.  
> “이런 방식은 피해야 한다”를 학습하는 것이 핵심.

### ❌ (1) Online Bigsize 패턴

- **실시간 서비스에서 너무 큰 모델**을 사용하는 경우.
- 예측 응답이 수 초 이상 걸리거나 서버 부팅이 느린 경우 문제 발생.

#### 문제점
- 응답 지연, 서버 부하, 비용 증가.
- 속도와 비용 간 Trade-off.

#### 대안
- 모델 경량화 / 캐싱 서버 도입 / 전처리 분리 / Batch 전환 고려.

---

### ❌ (2) All-in-one 패턴

- 여러 예측 모델을 **하나의 서버**에 동시에 올려 운영하는 방식.

#### 문제점
- 라이브러리 충돌 위험.
- 단일 장애점(SPOF, Single Point of Failure) 발생.
- 서버 다운 시 전체 서비스 중단.

#### 대안
- **모델별 독립 서버 구성 (Microservice Architecture)**  
- 필요에 따라 모델별로 스케일링.

---

## 📚 전체 요약

| 구분 | 설명 | 예시 |
|------|------|------|
| **Batch Serving** | 주기적 예측 후 DB 저장 | Netflix 추천 |
| **Online Serving** | 요청 시 즉시 예측 | YouTube, DeepL |
| **Web Single 패턴** | 단일 REST API 서버 | FastAPI, Flask |
| **Synchronous 패턴** | 요청 완료까지 대기 | 실시간 UI 반응 |
| **Asynchronous 패턴** | 메시지 큐 기반 비동기 처리 | Kafka, RabbitMQ |
| **Online Bigsize (Anti)** | 실시간에 대형 모델 사용 | 응답 지연 문제 |
| **All-in-one (Anti)** | 다중 모델을 단일 서버에 운영 | SPOF 발생 위험 |

---

## 🧩 Key Takeaways

- **Serving의 핵심은 “문제 상황에 맞는 아키텍처 선택”**  
- **Batch ↔ Online**, **Sync ↔ Async**는 트레이드오프 관계  
- **Anti 패턴을 인지하고 회피하는 능력**이 곧 ML 엔지니어링 실력  
- 향후 과제 선정 시,  
  - 데이터 주기성  
  - 모델 크기  
  - 응답 지연 허용 범위  
  - 개발 인력 규모  
  등을 기준으로 Serving 구조를 설계해야 함.

---

> 📖 Reference:  
> - NAVER Connect Foundation, *Product Serving: Serving의 정의와 다양한 패턴*  
> - Mercari ML System Design Patterns (https://mercari.github.io/ml-system-design-pattern/)
> - Github https://github.com/zzsza/Boostcamp-AI-Tech-Product-Serving